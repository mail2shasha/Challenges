{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Mon Jul 30 22:44:51 2018\n",
    "\n",
    "For Small data-set, Single hidden layer NN with dropout regularizer of 0.5/0.8\n",
    "\n",
    "@author: Shasha\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, Flatten\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_nn_model():\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size + 1, 32, input_length=max_len),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.8),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual model Evaluation with K-fold\n",
    "def cv_evaluate_nn_model(build_fn, X, y, nb_epoch=5, n_splits=5, batch_size=64, **kwargs):\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "    model = KerasClassifier(build_fn=build_fn, nb_epoch=nb_epoch, batch_size=batch_size, verbose=1)\n",
    "    results = cross_val_score(model, X, y, cv=kfold)\n",
    "    print('\\nModel average accuracy: {:.2f}'.format(results.mean()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_small = \"./dataset/training-data-small.txt\"\n",
    "test_small = \"./dataset/test-data-small.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the data in to a data frame and divide it in to Sample vs Label\n",
    "train_small_df = pd.read_csv(train_small, sep = '\\t', names = [\"Label\", \"Sample\"])\n",
    "\n",
    "train_small_df_sample_len = train_small_df.Sample.str.split(\",\").apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (train_small_df_sample_len)\n",
    "\n",
    "X_train, y = np.array(train_small_df.Sample), np.array(train_small_df.Label)\n",
    "\n",
    "#print (X_train[:3])\n",
    "\n",
    "test_small_df = pd.read_csv(test_small, sep = ' ', names = [\"Sample\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_small_df_sample_len = test_small_df.Sample.str.split(\",\").apply(len)\n",
    "\n",
    "X_test = np.array(test_small_df.Sample)\n",
    "\n",
    "# concatenate both train, test set to build the vocabulary\n",
    "X_all = np.concatenate((X_train, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tknzr = Tokenizer(lower = False, split = ',')\n",
    "tknzr.fit_on_texts(X_all)\n",
    "X_TrainSeqs = tknzr.texts_to_sequences(X_train)\n",
    "X_TestSeqs = tknzr.texts_to_sequences(X_test)\n",
    "\n",
    "#print (X_TestSeqs[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = train_small_df_sample_len.max() if train_small_df_sample_len.max() > test_small_df_sample_len.max() else test_small_df_sample_len.max()\n",
    "\n",
    "X_TrainSeqs = sequence.pad_sequences(X_TrainSeqs, maxlen=max_len)\n",
    "\n",
    "X_TestSeqs = sequence.pad_sequences(X_TestSeqs, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train seqs data size  (10000, 102)\n",
      "Size of vocab :  127\n"
     ]
    }
   ],
   "source": [
    "print (\"Train seqs data size \", X_TrainSeqs.shape)\n",
    "\n",
    "vocab_size = len(tknzr.word_counts)\n",
    "print (\"Size of vocab : \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization & Training \n",
    "model = single_nn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10000/10000 [==============================] - 5s 489us/step - loss: 0.1851 - acc: 0.9119\n",
      "Epoch 2/30\n",
      "10000/10000 [==============================] - 5s 478us/step - loss: 0.1864 - acc: 0.9102\n",
      "Epoch 3/30\n",
      "10000/10000 [==============================] - 5s 467us/step - loss: 0.1831 - acc: 0.9085\n",
      "Epoch 4/30\n",
      "10000/10000 [==============================] - 5s 491us/step - loss: 0.1715 - acc: 0.9186\n",
      "Epoch 5/30\n",
      "10000/10000 [==============================] - 5s 485us/step - loss: 0.1785 - acc: 0.9140\n",
      "Epoch 6/30\n",
      "10000/10000 [==============================] - 5s 489us/step - loss: 0.1731 - acc: 0.9183\n",
      "Epoch 7/30\n",
      "10000/10000 [==============================] - 5s 480us/step - loss: 0.1768 - acc: 0.9152\n",
      "Epoch 8/30\n",
      "10000/10000 [==============================] - 5s 472us/step - loss: 0.1730 - acc: 0.9156\n",
      "Epoch 9/30\n",
      "10000/10000 [==============================] - 5s 469us/step - loss: 0.1671 - acc: 0.9185\n",
      "Epoch 10/30\n",
      "10000/10000 [==============================] - 5s 482us/step - loss: 0.1694 - acc: 0.9172\n",
      "Epoch 11/30\n",
      "10000/10000 [==============================] - 4s 416us/step - loss: 0.1638 - acc: 0.9222\n",
      "Epoch 12/30\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.1599 - acc: 0.9243\n",
      "Epoch 13/30\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.1633 - acc: 0.9213\n",
      "Epoch 14/30\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.1644 - acc: 0.9226\n",
      "Epoch 15/30\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.1651 - acc: 0.9222\n",
      "Epoch 16/30\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.1546 - acc: 0.9255\n",
      "Epoch 17/30\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.1536 - acc: 0.9248\n",
      "Epoch 18/30\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.1566 - acc: 0.9249\n",
      "Epoch 19/30\n",
      "10000/10000 [==============================] - 5s 464us/step - loss: 0.1576 - acc: 0.9236\n",
      "Epoch 20/30\n",
      "10000/10000 [==============================] - 5s 478us/step - loss: 0.1596 - acc: 0.9227\n",
      "Epoch 21/30\n",
      "10000/10000 [==============================] - 5s 471us/step - loss: 0.1634 - acc: 0.9214\n",
      "Epoch 22/30\n",
      "10000/10000 [==============================] - 5s 476us/step - loss: 0.1544 - acc: 0.9274\n",
      "Epoch 23/30\n",
      "10000/10000 [==============================] - 5s 479us/step - loss: 0.1479 - acc: 0.9292\n",
      "Epoch 24/30\n",
      "10000/10000 [==============================] - 5s 481us/step - loss: 0.1505 - acc: 0.9278\n",
      "Epoch 25/30\n",
      "10000/10000 [==============================] - 5s 477us/step - loss: 0.1465 - acc: 0.9268\n",
      "Epoch 26/30\n",
      "10000/10000 [==============================] - 5s 481us/step - loss: 0.1471 - acc: 0.9291\n",
      "Epoch 27/30\n",
      "10000/10000 [==============================] - 5s 476us/step - loss: 0.1518 - acc: 0.9285\n",
      "Epoch 28/30\n",
      "10000/10000 [==============================] - 5s 480us/step - loss: 0.1474 - acc: 0.9290\n",
      "Epoch 29/30\n",
      "10000/10000 [==============================] - 5s 476us/step - loss: 0.1471 - acc: 0.9298\n",
      "Epoch 30/30\n",
      "10000/10000 [==============================] - 5s 473us/step - loss: 0.1439 - acc: 0.9283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9692e05e48>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_TrainSeqs, y, batch_size=32, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Prediction\n",
    "y_preds = model.predict(X_TestSeqs)\n",
    "y_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99646854], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
