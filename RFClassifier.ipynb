{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Python Packages\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset File Paths on local machine\n",
    "OUTPUT_PATH = \"./breast-cancer-wisconsin.csv\"\n",
    "\n",
    "#Headers\n",
    "Headers = [\"CodeNumber\", \"ClumpThickness\", \"UniformityCellSize\", \"UniformityCellShape\", \"MarginalAdhesion\", \"SingleEpithelialCellSize\", \"BareNuclei\", \"BlandChromatin\", \"NormalNucleoli\", \"Mitoses\", \"CancerType\"]\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_missings(dataset, missing_vals, drop_cols = []): \n",
    "    dataset.replace(missing_vals, np.NaN, inplace=True)\n",
    "    dataset.dropna(inplace=True)\n",
    "    #print (dataset['BareNuclei'].loc[25:])\n",
    "    #dataset.BareNuclei.hist(bins = 10)\n",
    "    #dataset.ClumpThickness.value_counts().plot(kind='barh')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_file_to_csv():\n",
    "    dataframe = pd.read_csv(url, delimiter = \",\", names = Headers)\n",
    "    #print (dataframe.describe())\n",
    "    dataframe.to_csv(OUTPUT_PATH, index=False)\n",
    "    #print (dataframe[dataframe.BareNuclei == \"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_input_fn(df, labels):\n",
    "    return tf.estimator.inputs.pandas_input_fn(x = df, queue_capacity = 1000,\n",
    "                                               y = labels, batch_size = 16, shuffle = True, num_epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_input_fn(df, labels):\n",
    "    return tf.estimator.inputs.pandas_input_fn(x = df, queue_capacity = 1000,\n",
    "                                               y = labels, batch_size = 16, shuffle = True, num_epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set features (580, 9) & label (580,) shapes\n",
      "Test set features (103, 9) & labels (103,) shapes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data_file_to_csv()\n",
    "dataset = pd.read_csv(OUTPUT_PATH)\n",
    "dataset = handle_missings(dataset, '?', Headers[6])\n",
    "#print (dataset['BareNuclei'].loc[23:])#.isna())#.isna())\n",
    "feature_headers = Headers[1:-1]\n",
    "target_label = Headers[-1]\n",
    "dataset['BareNuclei'] = dataset['BareNuclei'].astype(np.int64)#.size())#str.find(\"?\"))\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "dataset[target_label] = lab_enc.fit_transform(dataset[target_label]) #Encode labels with value between 0 and n_classes-1\n",
    "#print (dataset[target_label].unique())\n",
    "\n",
    "feat_columns = [tf.feature_column.numeric_column(k) for k in feature_headers]\n",
    "\n",
    "X_train, x_test, y_train, y_test = train_test_split(dataset[feature_headers], dataset[target_label], train_size=0.85)\n",
    "print (\"Train set features {} & label {} shapes\".format(X_train.shape, y_train.shape))\n",
    "print (\"Test set features {} & labels {} shapes\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_classifier():\n",
    "    model = tf.estimator.DNNClassifier(feature_columns=feat_columns, hidden_units=[32, 24, 6], model_dir = None, n_classes=2)\n",
    "    trained_model = model.train(input_fn=train_input_fn(X_train, y_train), steps=1000)\n",
    "    metrics = model.evaluate(input_fn=eval_input_fn(x_test, y_test), steps = 5)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trees_classifier():\n",
    "    model = tf.estimator.BoostedTreesClassifier(feature_columns=feat_columns,\n",
    "                                          n_batches_per_layer=5, n_trees = 300)\n",
    "    trained_model = model.train(input_fn=train_input_fn(X_train, y_train), max_steps=100)\n",
    "    metrics = model.evaluate(input_fn=eval_input_fn(x_test, y_test), steps=4)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-made DNNClassifier estimator results\n",
      "accuracy : 1.0\n",
      "accuracy_baseline : 0.65\n",
      "auc : 0.99999994\n",
      "auc_precision_recall : 0.99999994\n",
      "average_loss : 0.038199257\n",
      "global_step : 725\n",
      "label/mean : 0.35\n",
      "loss : 0.6111881\n",
      "precision : 1.0\n",
      "prediction/mean : 0.35063267\n",
      "recall : 1.0\n",
      "-----------------------------------------\n",
      "Pre-made Boosted Tree Classifier results\n",
      "accuracy 0.96875\n",
      "accuracy_baseline 0.703125\n",
      "auc 0.98362577\n",
      "auc_precision_recall 0.9551789\n",
      "average_loss 0.17750785\n",
      "global_step 100\n",
      "label/mean 0.296875\n",
      "loss 0.17750785\n",
      "precision 0.9047619\n",
      "prediction/mean 0.33555895\n",
      "recall 1.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    metrics_linear = linear_classifier()\n",
    "    print (\"Pre-made DNNClassifier estimator results\")\n",
    "    for key in sorted(metrics_linear):\n",
    "        print ('%s : %s' % (key, metrics_linear[key]))\n",
    "    metrics_boosted = trees_classifier()\n",
    "    print (\"-----------------------------------------\")\n",
    "    print (\"Pre-made Boosted Tree Classifier results\")    \n",
    "    for bkey in sorted(metrics_boosted):\n",
    "        print ('%s %s' % (bkey, metrics_boosted[bkey]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
